{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8caa3e9cfc4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mcrawler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWebCrawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[0mcrawler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SinUrl.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import mysql.connector\n",
    "import time\n",
    "   \n",
    "class WebCrawler():\n",
    "# Request Header\n",
    "    headers=requests.utils.default_headers()\n",
    "    headers.update(\n",
    "        {\n",
    "            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'\n",
    "        }\n",
    "    )\n",
    "#  Constructor  \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "# Storing Price with Url in database        \n",
    "    def storPriceUrl(self,asin,url,price,channel):\n",
    "        con=self.databaseCon()\n",
    "        if(channel==1):\n",
    "            try:\n",
    "                sql = \"INSERT INTO amazonprices (asin, url,price) VALUES (%s, %s,%s)\"\n",
    "                record = (sin, url,price)\n",
    "                amzcursor=con.cursor()\n",
    "                amzcursor.execute(sql, val)\n",
    "                con.commit()\n",
    "                \n",
    "            except error:\n",
    "                print(error)\n",
    "                \n",
    "            finally:\n",
    "                con.close()\n",
    "        \n",
    "    \n",
    "        \n",
    " # For DataBase Connection    \n",
    "    def databaseCon():\n",
    "        con = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        passwd=\"pythondb\"            \n",
    "        )\n",
    "        \n",
    "        return con\n",
    "    \n",
    "    \n",
    "# For Reading file    \n",
    "    def fileRead(self,path):\n",
    "        with open(path) as csvfile:\n",
    "            urlreader=csv.DictReader(csvfile,delimiter=',')\n",
    "            for url in urlreader:       \n",
    "                response=requests.get(url['URL'],headers=headers)\n",
    "                print(response)\n",
    "                data=BeautifulSoup(response.content,'lxml')\n",
    "                myData=data.find('div',attr={'id':'olpOfferListColumn'})\n",
    "                priceContainer=data.find_all('span',{'class':'a-size-large a-color-price olpOfferPrice a-text-bold'})\n",
    "                price=priceContainer[0].text.strip()\n",
    "                self.storPriceUrl(url['SIN'],url['URL'],price,1)\n",
    "                time.delay(5)\n",
    "        \n",
    "\n",
    "\n",
    "crawler=WebCrawler()\n",
    "crawler.fileRead(crawler,'SinUrl.csv')\n",
    "\n",
    "#     amzpricing=pd.DataFrame({'sin' : sinlist,\n",
    "#                                 'url' : urllist,\n",
    "#                                 'price' : pricelist})\n",
    "# # Saving in csv\n",
    "# # amzpricing.to_csv('AmazonPricing.csv')\n",
    "\n",
    "# #Saving in database\n",
    "# amzpricing.to_sql('amzprices', con = engine, if_exists = 'append', chunksize = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
